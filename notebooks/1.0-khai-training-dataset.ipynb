{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khai/malist_project/piano-transcribe\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khai/miniconda3/envs/malist_project/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from src.data.datasets import MAPSDataset\n",
    "from src.data.audio import MadmomSpectrogram\n",
    "from src.data.data_modules import MAPSDataModule\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_transform = MadmomSpectrogram(hop_length=441*4, sample_rate=16000)\n",
    "mapsDataModule = MAPSDataModule(batch_size=4, \n",
    "                                max_steps=5, \n",
    "                                sample_rate=16000, \n",
    "                                audio_transform=audio_transform, \n",
    "                                lazy_loading=True,\n",
    "                                hop_length = 441*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data \n",
    "mapsDataModule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = mapsDataModule.train_dataloader()\n",
    "validate_loader = mapsDataModule.val_dataloader()\n",
    "test_loader = mapsDataModule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 88])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0]['frames'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultiOutputClassifier(SGDClassifier(loss='log'))\n",
    "for i_batch,batch in enumerate(train_loader):\n",
    "    batch_input = torch.reshape(batch['audio'], [4, 5*294])\n",
    "    batch_output = batch['frames'][:,2,:]\n",
    "    clf.partial_fit(batch_input.numpy(), batch_output.numpy().astype(np.int), classes=[np.array([0,1]) for i in range(88)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accurary:  0.9094460227272728\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for batch in validate_loader:\n",
    "    batch_input = torch.reshape(batch['audio'], [batch['audio'].shape[0], 5*294])\n",
    "    batch_output = batch['frames'][:,2,:]\n",
    "    batch_pred = clf.predict(batch_input.numpy())\n",
    "    accuracy += accuracy_score(batch_output.numpy().astype(int).flatten(), batch_pred.flatten())\n",
    "\n",
    "print('Average accurary: ', accuracy/len(validate_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = MultiOutputClassifier(SGDClassifier(loss='hinge'))\n",
    "for i_batch,batch in enumerate(train_loader):\n",
    "    batch_input = torch.reshape(batch['audio'], [4, 5*294])\n",
    "    batch_output = batch['frames'][:,2,:]\n",
    "    svm_clf.partial_fit(batch_input.numpy(), batch_output.numpy().astype(np.int), classes=[np.array([0,1]) for i in range(88)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accurary:  0.9019886363636365\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for batch in validate_loader:\n",
    "    batch_input = torch.reshape(batch['audio'], [batch['audio'].shape[0], 5*294])\n",
    "    batch_output = batch['frames'][:,2,:]\n",
    "    batch_pred = svm_clf.predict(batch_input.numpy())\n",
    "    accuracy += accuracy_score(batch_output.numpy().astype(int).flatten(), batch_pred.flatten())\n",
    "\n",
    "print('Average accurary: ', accuracy/len(validate_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
